from fastapi import APIRouter, UploadFile, File, Depends, HTTPException
from PIL import Image
import io
import os
import models, crud
from crud import get_current_user
from huggingface_hub import hf_hub_download
import logging

router = APIRouter(prefix="/detect", tags=["Detect"])

logger = logging.getLogger(__name__)

# ===============================
# Global cache (‡πÑ‡∏°‡πà‡πÇ‡∏´‡∏•‡∏î‡∏ã‡πâ‡∏≥)
# ===============================
_yolo_model = None
_clip_model = None
_clip_processor = None

HF_TOKEN = os.getenv("HF_TOKEN")

# ===============================
# Lazy Load Function - YOLO
# ===============================
def get_yolo_model():
    """Lazy load YOLO model - ‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å HF ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"""
    global _yolo_model
    
    if _yolo_model is not None:
        return _yolo_model
    
    if not HF_TOKEN:
        logger.error("‚ùå HF_TOKEN not set")
        raise HTTPException(status_code=503, detail="HF_TOKEN not configured")
    
    try:
        logger.info("üì• Downloading YOLO model from HuggingFace...")
        from ultralytics import YOLO
        
        # ‡∏î‡∏∂‡∏á best.pt ‡∏à‡∏≤‡∏Å private HF repo
        yolo_weights = hf_hub_download(
            repo_id="freemanlnwza/modelYOLOv8",
            filename="weights/best.pt",
            token=HF_TOKEN,
            cache_dir="./models"
        )
        
        _yolo_model = YOLO(yolo_weights)
        logger.info("‚úÖ YOLO model loaded successfully")
        return _yolo_model
        
    except Exception as e:
        logger.error(f"‚ùå Error loading YOLO: {str(e)}")
        raise HTTPException(status_code=503, detail=f"YOLO model failed to load: {str(e)}")

# ===============================
# Lazy Load Function - CLIP
# ===============================
def get_clip_models():
    """Lazy load CLIP model + processor - ‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô (model, processor) ‡∏´‡∏£‡∏∑‡∏≠ (None, None)"""
    global _clip_model, _clip_processor
    
    if _clip_model is not None and _clip_processor is not None:
        return _clip_model, _clip_processor
    
    if not HF_TOKEN:
        logger.warning("‚ö†Ô∏è  HF_TOKEN not set - CLIP models will be skipped")
        return None, None
    
    try:
        logger.info("üì• Downloading CLIP model from HuggingFace...")
        # ‚úÖ Import torch ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (lazy load!)
        import torch
        from transformers import CLIPModel, CLIPProcessor
        
        # ‚úÖ ‡πÉ‡∏ä‡πâ token= (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà use_auth_token=)
        _clip_model = CLIPModel.from_pretrained(
            "freemanlnwza/modelCLIPfine-tuned",
            token=HF_TOKEN,
            trust_remote_code=True,
            torch_dtype=torch.float32  # ‚úÖ ‡πÉ‡∏ä‡πâ torch ‡∏ó‡∏µ‡πà import ‡∏Ç‡πâ‡∏≤‡∏á‡∏ö‡∏ô
        )
        
        _clip_processor = CLIPProcessor.from_pretrained(
            "freemanlnwza/modelCLIPfine-tuned",
            token=HF_TOKEN,
            trust_remote_code=True
        )
        
        logger.info("‚úÖ CLIP model loaded successfully")
        return _clip_model, _clip_processor
        
    except Exception as e:
        logger.error(f"‚ùå Error loading CLIP: {str(e)}")
        _clip_model = None
        _clip_processor = None
        return None, None

# ===============================
# Endpoint /frame
# ===============================
@router.post("/frame")
async def detect_frame(
    image: UploadFile = File(...),
    current_user: models.User = Depends(get_current_user)
):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û + ‡∏î‡∏∂‡∏á CLIP embedding
    - ‡∏î‡∏∂‡∏á YOLO + CLIP ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (lazy load)
    - ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ HF_TOKEN ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö private models
    """
    
    # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û
    if not image.filename:
        raise HTTPException(status_code=400, detail="No filename provided")
    
    if not image.filename.lower().endswith((".jpg", ".jpeg", ".png")):
        raise HTTPException(
            status_code=400, 
            detail="File must be an image (jpg, jpeg, png)"
        )

    # ‚úÖ ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô PIL
    try:
        image_bytes = await image.read()
        pil_image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    except Exception as e:
        logger.error(f"‚ùå Error reading image: {str(e)}")
        raise HTTPException(status_code=400, detail=f"Invalid image file: {str(e)}")

    # ===============================
    # YOLO detection (lazy load)
    # ===============================
    detections = []
    try:
        yolo_model = get_yolo_model()  # ‚úÖ ‡∏î‡∏∂‡∏á model ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ
        
        logger.info("üîç Running YOLO detection...")
        results = yolo_model.predict(pil_image, conf=0.5, verbose=False)
        
        # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ results ‡∏°‡∏µ boxes ‡πÑ‡∏´‡∏°
        if results and len(results) > 0 and len(results[0].boxes) > 0:
            for box in results[0].boxes:
                try:
                    x1, y1, x2, y2 = box.xyxy[0].tolist()
                    conf = float(box.conf[0])
                    cls = int(box.cls[0])
                    label = results[0].names[cls]
                    
                    detections.append({
                        "x1": round(x1, 2),
                        "y1": round(y1, 2),
                        "x2": round(x2, 2),
                        "y2": round(y2, 2),
                        "confidence": round(conf, 4),
                        "label": label
                    })
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  Error processing box: {str(e)}")
                    continue
                
            logger.info(f"‚úÖ Found {len(detections)} objects")
        else:
            logger.info("‚ö†Ô∏è  No objects detected")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå YOLO error: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Detection error: {str(e)}")

    # ===============================
    # CLIP embedding (lazy load + optional)
    # ===============================
    clip_embedding = None
    try:
        clip_model, clip_processor = get_clip_models()  # ‚úÖ ‡∏î‡∏∂‡∏á model ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ
        
        # ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ clip model load ‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°
        if clip_model is not None and clip_processor is not None:
            logger.info("üß† Generating CLIP embedding...")
            
            try:
                # ‚úÖ Import torch ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà (lazy load!)
                import torch
                
                inputs = clip_processor(
                    images=pil_image, 
                    return_tensors="pt"
                )
                
                with torch.no_grad():
                    # ‚úÖ ‡πÑ‡∏î‡πâ embedding ‡πÄ‡∏õ‡πá‡∏ô tensor
                    embedding = clip_model.get_image_features(**inputs)
                    # ‚úÖ Normalize embedding
                    embedding = embedding / embedding.norm(p=2, dim=-1, keepdim=True)
                    # ‚úÖ Convert to list
                    clip_embedding = embedding[0].tolist()
                    
                logger.info(f"‚úÖ CLIP embedding generated (dim: {len(clip_embedding)})")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  CLIP embedding generation failed: {str(e)}")
                clip_embedding = None
        else:
            logger.warning("‚ö†Ô∏è  CLIP model not available")
            
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è  CLIP embedding skipped: {str(e)}")
        clip_embedding = None

    return {
        "user": current_user.username,
        "detections": detections,
        "detections_count": len(detections),
        "clip_embedding": clip_embedding if clip_embedding else None,
        "embedding_dim": len(clip_embedding) if clip_embedding else None
    }

# ===============================
# Endpoint /status
# ===============================
@router.get("/status")
async def model_status(current_user: models.User = Depends(get_current_user)):
    """‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ Models"""
    
    yolo_loaded = _yolo_model is not None
    clip_loaded = _clip_model is not None
    
    return {
        "user": current_user.username,
        "yolo": {
            "status": "‚úÖ Loaded" if yolo_loaded else "‚ùå Not loaded",
            "note": "Will load on first use" if not yolo_loaded else "Ready to use"
        },
        "clip": {
            "status": "‚úÖ Loaded" if clip_loaded else "‚ùå Not loaded",
            "note": "Will load on first use" if not clip_loaded else "Ready to use"
        },
        "hf_token": "‚úÖ Set" if HF_TOKEN else "‚ùå Missing",
    }

# ===============================
# Endpoint /preload (optional)
# ===============================
@router.post("/preload")
async def preload_models(current_user: models.User = Depends(get_current_user)):
    """
    ‚úÖ Preload models ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ï‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (optional)
    ‡πÉ‡∏ä‡πâ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ warmup ‡πÄ‡∏°‡∏∑‡πà‡∏≠ API start
    """
    
    logger.info("üîÑ Preloading models...")
    
    results = {
        "yolo": None,
        "clip": None
    }
    
    # ‚úÖ Preload YOLO
    try:
        get_yolo_model()
        results["yolo"] = "‚úÖ YOLO preloaded"
    except Exception as e:
        results["yolo"] = f"‚ùå YOLO preload failed: {str(e)}"
    
    # ‚úÖ Preload CLIP
    try:
        clip_model, clip_processor = get_clip_models()
        if clip_model and clip_processor:
            results["clip"] = "‚úÖ CLIP preloaded"
        else:
            results["clip"] = "‚ö†Ô∏è  CLIP skipped (HF_TOKEN missing)"
    except Exception as e:
        results["clip"] = f"‚ùå CLIP preload failed: {str(e)}"
    
    return results